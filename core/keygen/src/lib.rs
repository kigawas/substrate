#![feature(async_closure)]

use client::backend::OffchainStorage;
use primitives::offchain::StorageKind;
use std::{
	collections::{BTreeMap, VecDeque},
	fmt::Debug,
	marker::Unpin,
	pin::Pin,
	sync::Arc,
	time::{Duration, Instant},
};

use mpe_primitives::ConsensusLog;
use primitives::traits::BareCryptoStore;

use codec::{Decode, Encode};
use curv::cryptographic_primitives::proofs::sigma_dlog::DLogProof;
use curv::cryptographic_primitives::secret_sharing::feldman_vss::VerifiableSS;
use curv::{FE, GE};

use futures03::channel::oneshot::{self, Canceled};
use futures03::compat::{Compat, Compat01As03};
use futures03::future::{FutureExt, TryFutureExt};
use futures03::prelude::{Future, Sink, Stream, TryStream};
use futures03::stream::{FilterMap, StreamExt, TryStreamExt};
use futures03::task::{Context, Poll};
use keystore::KeyStorePtr;
use log::{debug, error, info};
use mpe_primitives::ConsensusLog::RequestForKeygen;
use mpe_primitives::MP_ECDSA_ENGINE_ID;
use multi_party_ecdsa::protocols::multi_party_ecdsa::gg_2018::party_i::{
	KeyGenBroadcastMessage1 as KeyGenCommit, KeyGenDecommitMessage1 as KeyGenDecommit, Keys,
	Parameters, PartyPrivate, SharedKeys, SignKeys,
};
use parking_lot::RwLock;
use rand::prelude::Rng;
use tokio02::timer::Interval;

use client::{
	backend::Backend, error::Error as ClientError, error::Result as ClientResult, BlockchainEvents,
	CallExecutor, Client,
};
use consensus_common::SelectChain;
use inherents::InherentDataProviders;
use network::{self, PeerId};
use primitives::crypto::key_types::ECDSA_SHARED;
use primitives::{Blake2Hasher, H256};
use sr_primitives::generic::{BlockId, OpaqueDigestItemId};
use sr_primitives::traits::{Block as BlockT, DigestFor, Header, NumberFor, ProvideRuntimeApi};

mod communication;
mod periodic_stream;
// mod shared_state;
mod signer;

use communication::{
	gossip::{GossipMessage, MessageWithSender},
	message::{ConfirmPeersMessage, KeyGenMessage, PeerIndex, SignMessage},
	Network, NetworkBridge,
};
use periodic_stream::PeriodicStream;
// use shared_state::{load_persistent, set_signers, SharedState};
use signer::Signer;

type Count = u16;

#[derive(Debug)]
pub enum Error {
	Network(String),
	Periodic,
	Client(ClientError),
	Rebuild,
}

#[derive(Clone)]
pub struct NodeConfig {
	pub duration: u64,
	pub threshold: Count,
	pub players: Count,
	pub keystore: Option<KeyStorePtr>,
}

impl NodeConfig {
	pub fn get_params(&self) -> Parameters {
		Parameters {
			threshold: self.threshold,
			share_count: self.players,
		}
	}
}

#[derive(Debug)]
pub struct KeyGenState {
	pub complete: bool,
	pub local_key: Option<Keys>,
	pub commits: BTreeMap<PeerIndex, KeyGenCommit>,
	pub decommits: BTreeMap<PeerIndex, KeyGenDecommit>,
	pub vsss: BTreeMap<PeerIndex, VerifiableSS>,
	pub secret_shares: BTreeMap<PeerIndex, FE>,
	pub proofs: BTreeMap<PeerIndex, DLogProof>,
	pub shared_keys: Option<SharedKeys>,
}

impl KeyGenState {
	pub fn shared_public_key(&self) -> Option<GE> {
		self.shared_keys.clone().map(|sk| sk.y)
	}

	pub fn reset(&mut self) {
		*self = Self::default();
	}
}

impl Default for KeyGenState {
	fn default() -> Self {
		Self {
			complete: false,
			local_key: None,
			commits: BTreeMap::new(),
			decommits: BTreeMap::new(),
			vsss: BTreeMap::new(),
			secret_shares: BTreeMap::new(),
			proofs: BTreeMap::new(),
			shared_keys: None,
		}
	}
}

pub struct SigGenState {
	pub complete: bool,
	pub sign_key: Option<SignKeys>,
}

fn global_comm<Block, N>(
	bridge: &NetworkBridge<Block, N>,
	duration: u64,
) -> (
	impl Stream<Item = MessageWithSender>,
	impl Sink<MessageWithSender, Error = Error>,
)
where
	Block: BlockT<Hash = H256>,
	N: Network<Block> + Unpin,
	N::In: Send,
{
	let (global_in, global_out) = bridge.global();
	let global_in = PeriodicStream::<_, MessageWithSender>::new(global_in, duration);

	(global_in, global_out)
}

pub(crate) struct Environment<B, E, Block: BlockT, N: Network<Block>, RA, Storage> {
	pub client: Arc<Client<B, E, Block, RA>>,
	pub config: NodeConfig,
	pub bridge: NetworkBridge<Block, N>,
	pub state: Arc<RwLock<KeyGenState>>,
	pub offchain: Arc<RwLock<Storage>>,
}

use mpe_primitives::MAIN_DB_PREFIX;
pub const STORAGE_PREFIX: &[u8] = b"storage";
use primitives::crypto::Public;
use mpe_primitives::{get_data_prefix,get_key_prefix,get_complete_list_prefix,RequestId};
impl<B, E, Block: BlockT, N: Network<Block>, RA,Storage> Environment<B, E, Block, N, RA,Storage>
where Storage:OffchainStorage
{
	pub fn set_request_data(&self,request_id:RequestId,request_data:&[u8])
	{
		let  key:Vec<u8>=get_data_prefix(request_id);
		self.local_storage_set(StorageKind::PERSISTENT, &key, request_data)
	}
    pub fn set_request_complete(&self,request_id:RequestId) ->Result<(),&'static str>
	{
		let  key:Vec<u8>=get_complete_list_prefix();
		let mut reqs=Vec::<RequestId>::new();
        if let Some(data)=self.local_storage_get(&key)
		{
			reqs=match Decode::decode(&mut data.as_ref())
			{
				Ok(res) => res,
				Err(_) => return Err("Invalid data stored")
			}
		}
		reqs.push(request_id);
		reqs.sort();
		reqs.dedup();
        self.local_storage_set(StorageKind::PERSISTENT,&key,&reqs.encode());
		Ok(())
	}
	pub fn set_request_public_key<PK>(&self,request_id:RequestId,public_key:&PK) ->Result<(),&'static str>
	where PK:  Public
	{
		let  key:Vec<u8>=get_key_prefix(request_id);
		if let Some(_)=self.local_storage_get(&key)
		{
			return Err("Can only set key once per request")
		}
		self.local_storage_set(StorageKind::PERSISTENT, &key, public_key.as_slice())  ;
		self.set_request_complete(request_id)?;

		Ok(())

	}
	pub fn set_request_failure(&self,request_id:RequestId) ->Result<(),&'static str>
	{
		let mut key:Vec<u8>=get_key_prefix(request_id);
		if let Some(_)=self.local_storage_get(&key)
		{
			return Err("Can only set key/fail once per request")
		}
		let fail=[255u8;1];

		self.local_storage_set(StorageKind::PERSISTENT, &key, &fail) ;
		self.set_request_complete(request_id)?;

		Ok(())

	}

	pub fn local_storage_set(&self, kind: StorageKind, key: &[u8], value: &[u8]) {
		match kind {
			StorageKind::PERSISTENT => self.offchain.write().set(STORAGE_PREFIX, key, value),
			StorageKind::LOCAL => {},
		}
	}
	pub fn local_storage_get(&self,  key: &[u8]) -> Option<Vec<u8>>
	{
			self.offchain.read().get(STORAGE_PREFIX, key)
	}
	pub fn local_storage_compare_and_set(
		&self,
		kind: StorageKind,
		key: &[u8],
		old_value: Option<&[u8]>,
		new_value: &[u8],
	) -> bool {
		match kind {
			StorageKind::PERSISTENT => {
				self.offchain.write().compare_and_set(STORAGE_PREFIX, key, old_value, new_value)
			},
			StorageKind::LOCAL => false ,
		}
	}

}


struct KeyGenWork<B, E, Block: BlockT, N: Network<Block>, RA, Storage>
{
  key_gen: Pin<Box<dyn Future<Output = Result<(), Error>> + Send + Unpin>>,
  env: Arc<Environment<B, E, Block, N, RA, Storage>>,
}

impl<B, E, Block, N, RA, Storage> KeyGenWork<B, E, Block, N, RA, Storage>
where
	B: Backend<Block, Blake2Hasher> + 'static,
	E: CallExecutor<Block, Blake2Hasher> + Send + Sync + 'static,
	Block: BlockT<Hash = H256> + Unpin,
	Block::Hash: Ord,
	N: Network<Block> + Sync + Unpin,
	N::In: Send + 'static + Unpin,
	RA: Send + Sync + 'static,
	Storage: OffchainStorage + 'static,
{
	fn new(
		client: Arc<Client<B, E, Block, RA>>,
		config: NodeConfig,
		bridge: NetworkBridge<Block, N>,
		db: Storage,
	) -> Self {
		let state = KeyGenState::default();

		let env = Arc::new(Environment {
			client,
			config,
			bridge,
			state: Arc::new(RwLock::new(state)),
			offchain: Arc::new(RwLock::new(db)),
		});

		let mut work = Self {
			key_gen: Box::pin(futures03::future::pending()),
			env,
		};
		work.rebuild(true); // init should be okay
		work
	}

	fn rebuild(&mut self, last_message_ok: bool) {
		let (incoming, outgoing) = global_comm(&self.env.bridge, self.env.config.duration);
		let signer = Signer::new(self.env.clone(), incoming, outgoing, last_message_ok);

		self.key_gen = Box::pin(signer);
	}
}

impl<B, E, Block, N, RA, Storage> futures03::Future for KeyGenWork<B, E, Block, N, RA, Storage>
where
	B: Backend<Block, Blake2Hasher> + 'static,
	E: CallExecutor<Block, Blake2Hasher> + 'static + Send + Sync,
	Block: BlockT<Hash = H256> + Unpin,
	Block::Hash: Ord,
	N: Network<Block> + Send + Sync + Unpin + 'static,
	N::In: Send + 'static,
	RA: Send + Sync + 'static,
	Storage: OffchainStorage + 'static,
{
	type Output = Result<(), Error>;

	fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {
		println!("POLLLLLLLLLLLLLLLLLLLL");
		match self.key_gen.poll_unpin(cx) {
			Poll::Pending => {
				let (is_complete, is_canceled, commits_len) = {
					let state = self.env.state.read();
					let validator = self.env.bridge.validator.inner.read();

					println!(
						"INDEX {:?} state: commits {:?} decommits {:?} vss {:?} ss {:?}  proof {:?} has key {:?} complete {:?} peers hash {:?}",
						validator.get_local_index(),
						state.commits.len(),
						state.decommits.len(),
						state.vsss.len(),
						state.secret_shares.len(),
						state.proofs.len(),
						state.local_key.is_some(),
						state.complete,
						validator.get_peers_hash()
					);
					(
						validator.is_local_complete(),
						validator.is_local_canceled(),
						state.commits.len(),
					)
				};

				return Poll::Pending;
			}
			Poll::Ready(Ok(())) => {
				return Poll::Ready(Ok(()));
			}
			Poll::Ready(Err(e)) => {
				match e {
					Error::Rebuild => {
						println!("inner keygen rebuilt");
						self.rebuild(false);
						futures::task::current().notify();
						return Poll::Pending;
					}
					_ => {}
				}
				return Poll::Ready(Err(e));
			}
		}
	}
}

// pub fn init_shared_state<B, E, Block, RA>(client: Arc<Client<B, E, Block, RA>>) -> SharedState
// where
// 	B: Backend<Block, Blake2Hasher> + 'static,
// 	E: CallExecutor<Block, Blake2Hasher> + 'static + Clone + Send + Sync,
// 	Block: BlockT<Hash = H256>,
// 	Block::Hash: Ord,
// 	RA: Send + Sync + 'static,
// {
// 	let persistent_data: SharedState = load_persistent(&**client.backend()).unwrap();
// 	persistent_data
// }

pub fn run_key_gen<B, E, Block, N, RA>(
	local_peer_id: PeerId,
	(threshold, players): (PeerIndex, PeerIndex),
	duration: u64,
	keystore: KeyStorePtr,
	client: Arc<Client<B, E, Block, RA>>,
	network: N,
	backend: Arc<B>,
) -> ClientResult<impl Future<Output = Result<(), ()>> + Send + 'static>
where
	B: Backend<Block, Blake2Hasher> + 'static,
	E: CallExecutor<Block, Blake2Hasher> + 'static + Send + Sync,
	Block: BlockT<Hash = H256> + Unpin,
	Block::Hash: Ord,
	N: Network<Block> + Send + Sync + Unpin + 'static,
	N::In: Send + 'static,
	RA: Send + Sync + 'static,
{
  let keyclone = keystore.clone();
  let config = NodeConfig {
    threshold,
    players,
    keystore: Some(keystore),
    duration,
  };

  // let keystore = keystore.read();

  // let persistent_data: SharedState = load_persistent(&**client.backend()).unwrap();
  // println!("{:?}", persistent_data);
  // println!("Local peer ID {:?}", current_id.as_bytes());

  // let mut signers = persistent_data.signer_set;
  // let current_id = current_id.into_bytes();
  // if !signers.contains(&current_id) {
  // 	// if our id is not in it, add our self
  // 	signers.push(current_id);
  // 	set_signers(&**client.backend(), signers);
  // }
  let bridge = NetworkBridge::new(network, config.clone(), local_peer_id);
  let streamer=client.clone().import_notification_stream().for_each(move |n| {
		info!(target: "keygen", "HEADER {:?}, looking for consensus message", &n.header);
	        for log in n.header.digest().logs()
		{
		 info!(target: "keygen", "Checking log {:?}, looking for consensus message", log);
		 match log.try_as_raw(OpaqueDigestItemId::Consensus(&MP_ECDSA_ENGINE_ID))
		 {
			Some(data) => {
				info!("Got log id! {:?}",data);
		       let log_inner = log.try_to::<ConsensusLog>(OpaqueDigestItemId::Consensus(&MP_ECDSA_ENGINE_ID));
                info!("Got log inner! {:?}",log_inner);
				if let Some(log_in)=log_inner
				{
		       match log_in
			   {
				   RequestForKeygen((id,data)) =>
				   {
					  match keyclone.read().initiate_request(&id.to_be_bytes(),ECDSA_SHARED)
					  {
						  Ok(_) => {},
						  Err(e) =>debug!("Error in initiate request: {:?}",&e),
					  }

				   },
				   _ =>{}
			   }
				}
				//..ECDSA_SHARED KeyTypeId
			}
			info!(target: "substrate-log", "Imported with log called  #{} ({})", n.header.number(), n.hash);
			futures03::future::ready(())
		});

	let key_gen_work = KeyGenWork::new(
		client,
		config,
		bridge,
		backend
			.offchain_storage()
			.expect("Need offchain for keygen work"),
	)
	.map_err(|e| error!("Error {:?}", e));
	Ok(
		futures03::future::select(key_gen_work, streamer)
			.then(|_| futures03::future::ready(Ok(()))),
	)
}

#[cfg(test)]
mod tests;
